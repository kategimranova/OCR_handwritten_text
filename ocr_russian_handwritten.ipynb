{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install editdistance","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:13.231245Z","iopub.execute_input":"2023-03-28T08:13:13.234791Z","iopub.status.idle":"2023-03-28T08:13:23.036573Z","shell.execute_reply.started":"2023-03-28T08:13:13.234739Z","shell.execute_reply":"2023-03-28T08:13:23.035179Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Requirement already satisfied: editdistance in /opt/conda/lib/python3.7/site-packages (0.6.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport editdistance\nimport Levenshtein\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom torchvision import transforms\nimport os\nimport random\nfrom PIL import Image, ImageDraw\nimport json\nfrom IPython.display import clear_output\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.039608Z","iopub.execute_input":"2023-03-28T08:13:23.040038Z","iopub.status.idle":"2023-03-28T08:13:23.048600Z","shell.execute_reply.started":"2023-03-28T08:13:23.039992Z","shell.execute_reply":"2023-03-28T08:13:23.047473Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nlabels_val = pd.read_csv(\"/kaggle/input/datada1/archive-3/test.tsv\", sep='\\t', header=None)\nlabels_val.rename(columns={0:\"file_name\", 1:\"text\"}, inplace=True)\n\nlabels_train = pd.read_csv(\"/kaggle/input/datada1/archive-3/train.tsv\", sep='\\t', header=None)\nlabels_train.rename(columns={0:\"file_name\", 1:\"text\"}, inplace=True)\n\nlabels_train.dropna(inplace=True)\nlabels_val.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.050027Z","iopub.execute_input":"2023-03-28T08:13:23.050426Z","iopub.status.idle":"2023-03-28T08:13:23.166254Z","shell.execute_reply.started":"2023-03-28T08:13:23.050386Z","shell.execute_reply":"2023-03-28T08:13:23.165188Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"labels_train","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.169305Z","iopub.execute_input":"2023-03-28T08:13:23.170055Z","iopub.status.idle":"2023-03-28T08:13:23.183942Z","shell.execute_reply.started":"2023-03-28T08:13:23.170015Z","shell.execute_reply":"2023-03-28T08:13:23.182595Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"          file_name                   text\n0           aa1.png                Молдова\n1        aa1007.png      продолжила борьбу\n2         aa101.png          разработанные\n3        aa1012.png                  Плачи\n4        aa1013.png            Гимны богам\n...             ...                    ...\n72281  yob20539.png  Ответственность в/сл-\n72282  yob20543.png             независимо\n72283  yob20544.png    от воинского звания\n72284  yob20545.png               воинской\n72285  yob20546.png         должности рав-\n\n[72284 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa1.png</td>\n      <td>Молдова</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aa1007.png</td>\n      <td>продолжила борьбу</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aa101.png</td>\n      <td>разработанные</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa1012.png</td>\n      <td>Плачи</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aa1013.png</td>\n      <td>Гимны богам</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72281</th>\n      <td>yob20539.png</td>\n      <td>Ответственность в/сл-</td>\n    </tr>\n    <tr>\n      <th>72282</th>\n      <td>yob20543.png</td>\n      <td>независимо</td>\n    </tr>\n    <tr>\n      <th>72283</th>\n      <td>yob20544.png</td>\n      <td>от воинского звания</td>\n    </tr>\n    <tr>\n      <th>72284</th>\n      <td>yob20545.png</td>\n      <td>воинской</td>\n    </tr>\n    <tr>\n      <th>72285</th>\n      <td>yob20546.png</td>\n      <td>должности рав-</td>\n    </tr>\n  </tbody>\n</table>\n<p>72284 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def process_image(img, n_w=256, n_h=64):\n    w, h,_ = img.shape\n    new_w = n_h\n    new_h = int(h * (new_w / w))\n    img = cv2.resize(img, (new_h, new_w))\n    w, h,_ = img.shape\n    \n    if w < n_h:\n        add_zeros = np.full((n_h-w, h,3), 0)\n        img = np.concatenate((img, add_zeros))\n        w, h,_ = img.shape\n    \n    if h < n_w:\n        add_zeros = np.full((w, n_w-h,3), 0)\n        img = np.concatenate((img, add_zeros), axis=1)\n        w, h,_ = img.shape\n        \n    if h > n_w or w > n_h:\n        dim = (n_w,n_h)\n        img = cv2.resize(img, dim)\n\n    return img\n\ndef replace_black_to_white(image):\n    brown_lo = np.array([0,0,0])\n    brown_hi = np.array([0,0,0])\n\n    # Mask image to only select browns\n    mask = cv2.inRange(image,brown_lo,brown_hi)\n\n    # Change image to red where we found brown\n    image[mask>0] = (255,255,255)\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.185926Z","iopub.execute_input":"2023-03-28T08:13:23.186292Z","iopub.status.idle":"2023-03-28T08:13:23.197246Z","shell.execute_reply.started":"2023-03-28T08:13:23.186253Z","shell.execute_reply":"2023-03-28T08:13:23.195946Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class ExtraLinesAugmentation:\n    '''\n    Add random black lines to an image\n    Args:\n        number_of_lines (int): number of black lines to add\n        width_of_lines (int): width of lines\n    '''\n\n    def __init__(self, number_of_lines: int = 1, width_of_lines: int = 10):\n        self.number_of_lines = number_of_lines\n        self.width_of_lines = width_of_lines\n      \n    def __call__(self, img):\n        draw = ImageDraw.Draw(img)\n        for _ in range(self.number_of_lines):\n            x1 = random.randint(0, np.array(img).shape[1]); y1 = random.randint(0, np.array(img).shape[0])\n            x2 = random.randint(0, np.array(img).shape[1]); y2 = random.randint(0, np.array(img).shape[0])\n            draw.line((x1, y1, x2 + 100, y2), fill=(100, 0, 0), width=self.width_of_lines)\n\n        return img","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.199525Z","iopub.execute_input":"2023-03-28T08:13:23.200583Z","iopub.status.idle":"2023-03-28T08:13:23.209577Z","shell.execute_reply.started":"2023-03-28T08:13:23.200541Z","shell.execute_reply":"2023-03-28T08:13:23.208805Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def plot_loss_history(train_history, val_history, title='loss'):\n    plt.figure()\n    plt.title('{}'.format(title))\n    plt.plot(train_history, label='train', zorder=1)\n    \n    points = np.array(val_history)\n    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n    \n    plt.scatter(steps, val_history, marker='+', s=180, c='orange', label='val', zorder=2)\n    plt.xlabel('train steps')\n    \n    plt.legend(loc='best')\n    plt.grid()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.210991Z","iopub.execute_input":"2023-03-28T08:13:23.211825Z","iopub.status.idle":"2023-03-28T08:13:23.223206Z","shell.execute_reply.started":"2023-03-28T08:13:23.211787Z","shell.execute_reply":"2023-03-28T08:13:23.222378Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nconfig_json = {\n    \"alphabet\": \"\"\"@ !\"%'()+,-./0123456789:;=?AEFIMNOSTW[]abcdefghiklmnopqrstuvwxyАБВГДЕЖЗИКЛМНОПРСТУХЦЧШЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяё№\"\"\",\n    #\"alphabet\": \"\"\"@(),-.012345:;?I[]БВГДЗИКМНОПРСТУабвгдежзийклмнопрстуфхцчшщыьэюяё\"\"\",\n    \"save_dir\": \"/kaggle/working/data/experiments/test\",\n    \"num_epochs\": 100,\n    #\"num_epochs\": 500,\n    \"image\": {\n        \"width\": 256,\n        \"height\": 64\n    },\n    \"train\": {\n        \"root_path\": \"/kaggle/input/datada1/archive-3/train\",\n        \"batch_size\": 64\n    },\n    \"val\": {\n        \"root_path\": \"/kaggle/input/datada1/archive-3/test\",\n        \"batch_size\": 128\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.224840Z","iopub.execute_input":"2023-03-28T08:13:23.225277Z","iopub.status.idle":"2023-03-28T08:13:23.234976Z","shell.execute_reply.started":"2023-03-28T08:13:23.225239Z","shell.execute_reply":"2023-03-28T08:13:23.234007Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def process_row(text):\n    text = text.replace(' ', '|')\n    text = list(text)\n    for i in range(len(text)):\n        if text[i] not in config_json['alphabet'] and text[i] != '|':\n            text[i] = '@'\n    return \" \".join(text)\ndef prepare_labels(path):\n    lines = [line.rstrip() for line in open(path)]\n    arr = []\n    for line in lines:\n        arr.append([line.split('\\t')[0], line.split('\\t')[1]])\n    return arr","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.236409Z","iopub.execute_input":"2023-03-28T08:13:23.237236Z","iopub.status.idle":"2023-03-28T08:13:23.248570Z","shell.execute_reply.started":"2023-03-28T08:13:23.237199Z","shell.execute_reply":"2023-03-28T08:13:23.247553Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def black2white(image):\n    lo=np.array([0,0,0])\n\n    hi=np.array([0,0,0])\n\n    mask = cv2.inRange(image, lo, hi)\n\n    image[mask>0]=(255,255,255)\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.253215Z","iopub.execute_input":"2023-03-28T08:13:23.253727Z","iopub.status.idle":"2023-03-28T08:13:23.259763Z","shell.execute_reply.started":"2023-03-28T08:13:23.253699Z","shell.execute_reply":"2023-03-28T08:13:23.258553Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# функция которая помогает объединять картинки и таргет-текст в батч\ndef collate_fn(batch):\n    images, texts, enc_texts = zip(*batch)\n    images = torch.stack(images, 0)\n    text_lens = torch.LongTensor([len(text) for text in texts])\n    enc_pad_texts = pad_sequence(enc_texts, batch_first=True, padding_value=0)\n    return images, texts, enc_pad_texts, text_lens\ndef collate_fn_val(batch):\n    images, texts, enc_texts = zip(*batch)\n    images = torch.stack(images, 0)\n    text_lens = torch.LongTensor([len(text) for text in texts])\n    enc_pad_texts = pad_sequence(enc_texts, batch_first=True, padding_value=0)\n    return images, texts, enc_pad_texts, text_lens\n\n\ndef get_data_loader(\n    transforms, df, root_path, tokenizer, batch_size, drop_last, config, train, shuffle=False\n):\n    dataset = OCRDataset(df, root_path, tokenizer, config, train, transforms)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        collate_fn=collate_fn,\n        batch_size=batch_size,\n        num_workers=4,\n        shuffle=shuffle\n    )\n    return data_loader\n\ndef get_data_loader_val(\n    transforms, df, root_path, tokenizer, batch_size, drop_last, config, train, shuffle=False\n):\n    dataset = OCRDataset(df, root_path, tokenizer, config, train, transforms)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        collate_fn=collate_fn_val,\n        batch_size=batch_size,\n        num_workers=4,\n        shuffle=shuffle\n    )\n    return data_loader\n\ndef prepare_val_image(image, transform1, transform2):\n    image3 = image.astype(np.uint8)\n    image3 = Image.fromarray(image3)\n    image3 = transform1(image3)\n    image3 = np.array(image3).astype(np.int64)\n    image3 = transform2(image3)\n    return image3\n\nclass OCRDataset(Dataset):\n    \n    def __init__(self, df, root_path, tokenizer, config, train=False, transform=None):\n        super().__init__()\n        self.transform = transform\n        self.config = config\n        self.df = df\n        self.data_len = len(self.df)\n        self.train = train\n        self.train_transform = transforms.Compose([\n            ExtraLinesAugmentation(number_of_lines=3,\n                                   width_of_lines=8),                         \n            transforms.RandomAffine(degrees=0,\n                                    scale=(0.935, 0.935)),\n                                    #fill=0),\n                                    #fillcolor=0),\n            transforms.RandomCrop((self.config['image']['height'], self.config['image']['width'])),\n            transforms.RandomRotation(degrees=(-12, 12),\n                                      fill=255),])\n        self.img_paths = []\n        self.texts = []\n        for i in range(self.data_len):\n            self.img_paths.append(os.path.join(root_path, self.df['file_name'].iloc[i]))\n            self.texts.append(self.df['text'].iloc[i])\n        '''\n        for text in self.texts:\n            try:\n                tokenizer.encode(text)\n            except Exception as e:\n                print(e)\n                print(text)'''\n        self.enc_texts = tokenizer.encode(self.texts)\n        \n    def __len__(self):\n        return self.data_len\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        text = self.texts[idx]\n        enc_len = 32\n        enc_text = self.enc_texts[idx][:enc_len]\n        enc_text = enc_text + [0] * (enc_len - len(enc_text))\n        enc_text = torch.LongTensor(enc_text)\n        image = black2white(cv2.imread(img_path))\n        \n        if self.train:\n            #image = self.blots(image)\n            image = process_image(image,\n                                  int(self.config['image']['width'] * 1.05),\n                                  int(self.config['image']['height'] * 1.05))\n            \n            image = image.astype(np.uint8)\n            image = Image.fromarray(image)\n            image = self.train_transform(image)\n            image = np.array(image).astype(np.int64)\n        else:\n            image = process_image(image, self.config['image']['width'], self.config['image']['height'])\n        if self.transform is not None:\n            image = self.transform(image)\n        if self.train:\n            image = image ** (random.random() * 0.7 + 0.6)\n        if self.train == False:\n            return image, text, enc_text\n        else:\n            return image, text, enc_text\n\n\nclass AverageMeter:\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.261665Z","iopub.execute_input":"2023-03-28T08:13:23.262427Z","iopub.status.idle":"2023-03-28T08:13:23.286231Z","shell.execute_reply.started":"2023-03-28T08:13:23.262385Z","shell.execute_reply":"2023-03-28T08:13:23.285167Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"CTC_BLANK = '<BLANK>'\n\ndef get_char_map(alphabet):\n    \"\"\"Make from string alphabet character2int dict.\n    Add BLANK char fro CTC loss and OOV char for out of vocabulary symbols.\"\"\"\n    char_map = {value: idx + 1 for (idx, value) in enumerate(alphabet)}\n    char_map[CTC_BLANK] = 0\n    return char_map\n\n\nclass Tokenizer:\n    \"\"\"Class for encoding and decoding string word to sequence of int\n    (and vice versa) using alphabet.\"\"\"\n\n    def __init__(self, alphabet):\n        self.char_map = get_char_map(alphabet)\n        self.rev_char_map = {val: key for key, val in self.char_map.items()}\n\n    def encode(self, word_list):\n        \"\"\"Returns a list of encoded words (int).\"\"\"\n        enc_words = []\n        for word in word_list:\n            enc_words.append(\n                [self.char_map[char] if char in self.char_map\n                 else 1\n                 for char in word]\n            )\n        return enc_words\n\n    def get_num_chars(self):\n        return len(self.char_map)\n\n    def decode(self, enc_word_list):\n        \"\"\"Returns a list of words (str) after removing blanks and collapsing\n        repeating characters. Also skip out of vocabulary token.\"\"\"\n        dec_words = []\n        for word in enc_word_list:\n            word_chars = ''\n            for idx, char_enc in enumerate(word):\n                # skip if blank symbol, oov token or repeated characters\n                if (\n                    char_enc != self.char_map[CTC_BLANK]\n                    # idx > 0 to avoid selecting [-1] item\n                    and not (idx > 0 and char_enc == word[idx - 1])\n                ):\n                    word_chars += self.rev_char_map[char_enc]\n            dec_words.append(word_chars)\n        return dec_words\n    def decode_after_beam(self, enc_word_list):\n        \"\"\"Returns a list of words (str) after removing blanks and collapsing\n        repeating characters. Also skip out of vocabulary token.\"\"\"\n        dec_words = []\n        for word in enc_word_list:\n            word_chars = ''\n            for idx, char_enc in enumerate(word):\n                word_chars += self.rev_char_map[char_enc]\n            dec_words.append(word_chars)\n        return dec_words","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.287728Z","iopub.execute_input":"2023-03-28T08:13:23.288080Z","iopub.status.idle":"2023-03-28T08:13:23.302398Z","shell.execute_reply.started":"2023-03-28T08:13:23.288041Z","shell.execute_reply":"2023-03-28T08:13:23.301168Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def get_accuracy(y_true, y_pred):\n    scores = []\n    for true, pred in zip(y_true, y_pred):\n        scores.append(true == pred)\n    avg_score = np.mean(scores)\n    return avg_score","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.304064Z","iopub.execute_input":"2023-03-28T08:13:23.304542Z","iopub.status.idle":"2023-03-28T08:13:23.316842Z","shell.execute_reply.started":"2023-03-28T08:13:23.304482Z","shell.execute_reply":"2023-03-28T08:13:23.315749Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"class Normalize:\n    def __call__(self, img):\n        img = img.astype(np.float32) / 255\n        return img\n\n\nclass ToTensor:\n    def __call__(self, arr):\n        arr = torch.from_numpy(arr)\n        return arr\n\n\nclass MoveChannels:\n    \"\"\"Move the channel axis to the zero position as required in pytorch.\"\"\"\n\n    def __init__(self, to_channels_first=True):\n        self.to_channels_first = to_channels_first\n\n    def __call__(self, image):\n        if self.to_channels_first:\n            return np.moveaxis(image, -1, 0)\n        else:\n            return np.moveaxis(image, 0, -1)\n\n\nclass ImageResize:\n    def __init__(self, height, width):\n        self.height = height\n        self.width = width\n\n    def __call__(self, image):\n        image = cv2.resize(image, (self.width, self.height),\n                           interpolation=cv2.INTER_LINEAR)\n        return image\n\n\n\ndef get_train_transforms(height, width):\n    transforms = torchvision.transforms.Compose([\n        #ImageResize(height, width),\n        \n        MoveChannels(to_channels_first=True),\n        Normalize(),\n        ToTensor()\n    ])\n    return transforms\n\n\ndef get_val_transforms(height, width):\n    transforms = torchvision.transforms.Compose([\n        #ImageResize(height, width),\n        MoveChannels(to_channels_first=True),\n        Normalize(),\n        ToTensor()\n    ])\n    return transforms","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.318336Z","iopub.execute_input":"2023-03-28T08:13:23.319348Z","iopub.status.idle":"2023-03-28T08:13:23.330190Z","shell.execute_reply.started":"2023-03-28T08:13:23.319311Z","shell.execute_reply":"2023-03-28T08:13:23.329409Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def get_resnet34_backbone(pretrained=True):\n    m = torchvision.models.resnet34(pretrained=True)\n    input_conv = nn.Conv2d(3, 64, 7, 1, 3)\n    blocks = [input_conv, m.bn1, m.relu,\n              m.maxpool, m.layer1, m.layer2, m.layer3]\n    return nn.Sequential(*blocks)\ndef get_resnet50_backbone(pretrained=True):\n    m = torchvision.models.resnet50(pretrained=True)\n    input_conv = nn.Conv2d(3, 64, 7, 1, 3)\n    blocks = [input_conv, m.bn1, m.relu,\n              m.maxpool, m.layer1, m.layer2, m.layer3]\n    return nn.Sequential(*blocks)\n\nclass BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout=0.1):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers,\n            dropout=dropout, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.331518Z","iopub.execute_input":"2023-03-28T08:13:23.332580Z","iopub.status.idle":"2023-03-28T08:13:23.345037Z","shell.execute_reply.started":"2023-03-28T08:13:23.332540Z","shell.execute_reply":"2023-03-28T08:13:23.344298Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"class CRNN_RESNET(nn.Module):\n    def __init__(\n        self, number_class_symbols, out_len=32\n    ):\n        super().__init__()\n        self.feature_extractor = get_resnet34_backbone(pretrained=True)\n        # веса resnet34 получаются из этого гитхаба https://github.com/lolpa1n/digital-peter-ocrv \n        #self.feature_extractor.load_state_dict(torch.load('../input/ocr-resnet/resnet_ocr.pt')) \n        self.avg_pool = nn.AdaptiveAvgPool2d(\n            (512, out_len))\n        self.bilstm = BiLSTM(512, 256, 2)\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, number_class_symbols)\n        )\n    def forward(self, x, return_x=False):\n        feature = self.feature_extractor(x)\n        b, c, h, w = feature.size()\n        feature = feature.view(b, c * h, w)\n        feature = self.avg_pool(feature)\n        feature = feature.transpose(1, 2)\n        out = self.bilstm(feature)\n        #print(x.shape)\n        out = self.classifier(out)\n        \n\n        x1 = nn.functional.log_softmax(out, dim=2).permute(1, 0, 2)\n        if return_x:\n            return x1, out\n        else:\n            return x1","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.346425Z","iopub.execute_input":"2023-03-28T08:13:23.347108Z","iopub.status.idle":"2023-03-28T08:13:23.359174Z","shell.execute_reply.started":"2023-03-28T08:13:23.347072Z","shell.execute_reply":"2023-03-28T08:13:23.358527Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\n\ndef val_loop(data_loader, model, criterion, tokenizer, device):\n    acc_avg = AverageMeter()\n    loss_avg = AverageMeter()\n    error_chars = 0\n    error_words = 0\n    criterion2 = nn.CrossEntropyLoss()\n    total_string = 0\n    ctc_weight = 0.9\n    for images, texts, enc_pad_texts, text_lens in tqdm(data_loader):\n        #print(\"мы зашли в цикл\")\n        batch_size = len(texts)\n        enc_pad_texts2 = deepcopy(enc_pad_texts.view(-1)).cuda()\n        text_preds, output, output2 = predict(images, model, tokenizer, device, return_output=True)\n        output_lenghts = torch.full(\n            size=(output.size(1),),\n            fill_value=output.size(0),\n            dtype=torch.long\n        )\n        try:\n            loss1 = criterion(output, enc_pad_texts, output_lenghts, text_lens).mean()\n        except Exception as e:\n            #print(f\"val: {e}\")\n            continue\n        output2 = output2.view(output2.shape[0] * output2.shape[1], output2.shape[2])\n        loss2 = criterion2(output2,\n                           enc_pad_texts2)\n        loss = ctc_weight * loss1 + (1.0 - ctc_weight) * loss2\n        loss_avg.update(loss.item(), batch_size)\n        for i in range(batch_size):\n            total_string += 1\n            error_chars += (editdistance.eval(text_preds[i], texts[i]) / len(texts[i]))\n            words_text_preds = text_preds[i].split()\n            words_texts = texts[i].split()\n            error_words += Levenshtein.distance(words_text_preds, words_texts) / len(words_texts)\n            '''\n            if text_preds[i] != texts[i]:\n                print('----------------')\n                print(f'true: {texts[i]}')\n                print(f'pred: {text_preds[i]}')\n            '''\n        acc_avg.update(get_accuracy(texts, text_preds), batch_size)\n    print(f\"Val loss average: {loss_avg.avg}\")\n    print(f'Validation, acc: {acc_avg.avg:.4f}')\n    print(f\"CER: {error_chars / total_string * 100}%\")\n    print(f\"WER: {error_words / total_string * 100}%\")\n    #loss, cer, wer, acc\n    return loss_avg.avg, error_chars / total_string, error_words / total_string, acc_avg.avg\n\ndef train_loop(data_loader, model, criterion, optimizer, epoch, train_history=[]):\n    loss_avg = AverageMeter()\n    model.train()\n    criterion2 = nn.CrossEntropyLoss()\n    ctc_weight = 0.9\n    i = 0\n    for images, texts, enc_pad_texts, text_lens in tqdm(data_loader):\n        model.zero_grad()\n        images = images.to(DEVICE)\n        enc_pad_texts2 = deepcopy(enc_pad_texts.view(-1)).cuda()\n        batch_size = len(texts)\n        output, output2 = model(images, True)\n        output_lenghts = torch.full(\n            size=(output.size(1),),\n            fill_value=output.size(0),\n            dtype=torch.long\n        )\n        #print(output.permute(1, 0, 2).shape, enc_pad_texts.shape)\n        #enc_pad_texts2 = []\n        #second_loss = criterion2(output.permute(1, 0, 2), enc_pad_texts)\n        enc_pad_texts = enc_pad_texts.flatten()  # make 1dim, the doc says we can do it\n        enc_pad_texts = enc_pad_texts[enc_pad_texts != 0]  # drop blank dims\n        try:\n            loss1 = criterion(output, enc_pad_texts, output_lenghts, text_lens).mean()#(criterion(output, enc_pad_texts, output_lenghts, text_lens).mean() + second_loss) / 2\n        except Exception as e:\n            #print(f\"train: {e}\")\n            continue\n        output2 = output2.view(output2.shape[0] * output2.shape[1], output2.shape[2])\n        loss2 = criterion2(output2, enc_pad_texts2)\n        loss = ctc_weight * loss1 + (1.0 - ctc_weight) * loss2    \n        loss_avg.update(loss.item(), batch_size)\n        train_history.append(loss.item())\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n        optimizer.step()\n        if i % 100 == 0:\n            print('train_loss =', loss)\n        i += 1\n    for param_group in optimizer.param_groups:\n        lr = param_group['lr']\n    print(f'\\nEpoch {epoch}, Loss: {loss_avg.avg:.5f}, LR: {lr:.7f}')\n    return loss_avg.avg, train_history\n\n\ndef predict(images, model, tokenizer, device, return_output=False):\n    model.eval()\n    images = images.to(device)\n    #print(images.shape)\n    with torch.no_grad():\n        output, output2 = model(images, True)\n    #output = process_output(output)\n    pred = torch.argmax(output.detach().cpu(), -1).permute(1, 0).numpy()\n    text_preds = tokenizer.decode(pred)\n    if return_output:\n        return text_preds, output, output2\n    else:\n        return text_preds\n\n\ndef get_loaders(tokenizer, config, labels_train, labels_val):\n    train_transforms = get_train_transforms(\n        height=config['image']['height'],\n        width=config['image']['width']\n    )\n    train_loader = get_data_loader(\n        df=labels_train,\n        root_path=config['train']['root_path'],\n        transforms=train_transforms,\n        tokenizer=tokenizer,\n        batch_size=config['train']['batch_size'],\n        drop_last=True,\n        config=config,\n        train=True,\n        shuffle=True\n\n    )\n    val_transforms = get_val_transforms(\n        height=config['image']['height'],\n        width=config['image']['width']\n    )\n    val_loader = get_data_loader_val(\n        df=labels_val,\n        transforms=val_transforms,\n        root_path=config['val']['root_path'],\n        tokenizer=tokenizer,\n        batch_size=config['val']['batch_size'],\n        drop_last=False,\n        config=config,\n        train=False,\n        shuffle=False\n    )\n    return train_loader, val_loader\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.360988Z","iopub.execute_input":"2023-03-28T08:13:23.361687Z","iopub.status.idle":"2023-03-28T08:13:23.386617Z","shell.execute_reply.started":"2023-03-28T08:13:23.361649Z","shell.execute_reply":"2023-03-28T08:13:23.385546Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(config_json['alphabet'])\nos.makedirs(config_json['save_dir'], exist_ok=True)\ntrain_loader, val_loader = get_loaders(tokenizer, config_json, labels_train, labels_val)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:23.388167Z","iopub.execute_input":"2023-03-28T08:13:23.388606Z","iopub.status.idle":"2023-03-28T08:13:25.922532Z","shell.execute_reply.started":"2023-03-28T08:13:23.388559Z","shell.execute_reply":"2023-03-28T08:13:25.921448Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"tokenizer.get_num_chars()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:25.924033Z","iopub.execute_input":"2023-03-28T08:13:25.925080Z","iopub.status.idle":"2023-03-28T08:13:25.932942Z","shell.execute_reply.started":"2023-03-28T08:13:25.925041Z","shell.execute_reply":"2023-03-28T08:13:25.931351Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"124"},"metadata":{}}]},{"cell_type":"code","source":"model = CRNN_RESNET(tokenizer.get_num_chars(), 32)\nmodel.to(DEVICE)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:25.935391Z","iopub.execute_input":"2023-03-28T08:13:25.936612Z","iopub.status.idle":"2023-03-28T08:13:26.399414Z","shell.execute_reply.started":"2023-03-28T08:13:25.936572Z","shell.execute_reply":"2023-03-28T08:13:26.398338Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"CRNN_RESNET(\n  (feature_extractor): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (avg_pool): AdaptiveAvgPool2d(output_size=(512, 32))\n  (bilstm): BiLSTM(\n    (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=512, out_features=256, bias=True)\n    (1): GELU(approximate='none')\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=256, out_features=124, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = torch.nn.CTCLoss(blank=0, reduction='none', zero_infinity=True)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001,\n                                  weight_decay=0.01)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer=optimizer, mode='min', factor=0.5, patience=2)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:26.400904Z","iopub.execute_input":"2023-03-28T08:13:26.404029Z","iopub.status.idle":"2023-03-28T08:13:26.411258Z","shell.execute_reply.started":"2023-03-28T08:13:26.403992Z","shell.execute_reply":"2023-03-28T08:13:26.409896Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:26.412519Z","iopub.execute_input":"2023-03-28T08:13:26.412833Z","iopub.status.idle":"2023-03-28T08:13:26.426700Z","shell.execute_reply.started":"2023-03-28T08:13:26.412793Z","shell.execute_reply":"2023-03-28T08:13:26.425564Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"best_cer = np.inf\nbest_wer = np.inf\nbest_loss = np.inf\nbest_epoch = 0\ntrain_history = []\nval_history = []\nval_loop(val_loader, model, criterion, tokenizer, DEVICE)\nfor epoch in tqdm(range(config_json['num_epochs'])):\n    print(\"num of epoch\", epoch)\n    loss_avg, train_history = train_loop(train_loader, model, criterion, optimizer, epoch, train_history)\n    print('average_train_loss', loss_avg)\n    val_loss_avg, cer_avg, wer_avg, acc_avg = val_loop(val_loader, model, criterion, tokenizer, DEVICE)\n    val_history.append(val_loss_avg)\n    scheduler.step(cer_avg)\n    if cer_avg < best_cer:\n        best_cer = cer_avg\n        best_wer = wer_avg\n        best_epoch = epoch\n        best_loss = val_loss_avg\n        model_save_path = os.path.join(\n            config_json['save_dir'], f'model-{epoch}-{cer_avg:.4f}.ckpt')\n        torch.save(model.state_dict(), model_save_path)\n        print('Model weights saved')\n    clear_output()\n    for param_group in optimizer.param_groups:\n        lr = param_group['lr']\n    print(f'Current CER = {cer_avg}')\n    print(f'Current WER = {wer_avg}')\n    print(f'Current loss = {val_loss_avg}')\n    print(f'Current acc_avg = {acc_avg}')\n    print(f'Current learning rate = {lr}')\n    print('-' * 20)\n    print(f'Best CER = {best_cer}')\n    print(f'Best WER = {best_wer}')\n    print(f'Best loss = {best_loss}')\n    print(f'Best epoch = {best_epoch}')\n    plot_loss_history(train_history, val_history)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T08:13:26.428599Z","iopub.execute_input":"2023-03-28T08:13:26.428983Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Current CER = 0.33362848230118786\nCurrent WER = 0.8881152849740934\nCurrent loss = 11.368099756191432\nCurrent acc_avg = 0.0822538860103627\nCurrent learning rate = 0.001\n--------------------\nBest CER = 0.33362848230118786\nBest WER = 0.8881152849740934\nBest loss = 11.368099756191432\nBest epoch = 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"num of epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1130 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e06c9735a9448efaab777eaa2f97890"}},"metadata":{}},{"name":"stdout","text":"train_loss = tensor(8.7214, device='cuda:0', grad_fn=<AddBackward0>)\ntrain_loss = tensor(6.6532, device='cuda:0', grad_fn=<AddBackward0>)\ntrain_loss = tensor(7.6632, device='cuda:0', grad_fn=<AddBackward0>)\ntrain_loss = tensor(8.8819, device='cuda:0', grad_fn=<AddBackward0>)\ntrain_loss = tensor(7.8313, device='cuda:0', grad_fn=<AddBackward0>)\n","output_type":"stream"}]}]}